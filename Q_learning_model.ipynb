{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1FtW9fQb2PoJbSZAxQ4kBSbNWHLNbN20K",
      "authorship_tag": "ABX9TyONJ5DmcnlpOjz2lhbEqSEI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jatink121/FINSEARCH_Jatin/blob/main/Q_learning_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Important **Libraies**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TfiR2T-WM1T9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9UDtmXRXu7Xu"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/NIFTY 50_Data - NIFTY 50_Data.csv'\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading **Data**"
      ],
      "metadata": {
        "id": "aJuwQyUsM8Uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "Stock_price = df['Avg']\n",
        "data  = Stock_price[::-1]"
      ],
      "metadata": {
        "id": "b7XjzEy3uxSd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model with a budget constraint**"
      ],
      "metadata": {
        "id": "WYxTWEoxNDsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#Here we define state of the stocks for now i have simply chosen state to include stock price\n",
        "#will update it later to consider other things too\n",
        "\n",
        "class State :\n",
        "  def __init__(self):\n",
        "    self.prev_val = None\n",
        "    self.next_val = None\n",
        "    self.val = None\n",
        "    self.avg= None\n",
        "    self.volume = None\n",
        "    self.q_index = None\n",
        "\n",
        "\n",
        "#This is a function which randomizes the action function\n",
        "def take_random_action (n, budget) :\n",
        "  if budget <=12500 :\n",
        "    return np.random.randint(1,2)\n",
        "  if n==0 :\n",
        "    return np.random.randint(0,2)\n",
        "  action = np.random.randint(0,3)\n",
        "  return action\n",
        "\n",
        "\n",
        "#here we define the reward function for now we are choosing the reward function to be simply PnL\n",
        "#Can be modified later\n",
        "def get_reward(present_state,Post_state,action,buy_price,n, budget) :\n",
        "  min_budget = 1000\n",
        "  penalty_factor = -1\n",
        "  if action==0 :                              #  buy\n",
        "    PnL = (Post_state-present_state)*(n-1)\n",
        "    buy_price+=present_state\n",
        "    #PnL = (PnL/buy_price)*100\n",
        "    n+=1\n",
        "    budget-=present_state\n",
        "  elif action ==2 and n !=0 :                             #sell\n",
        "    PnL = (n*present_state - buy_price)\n",
        "    #PnL = (PnL/buy_price) * 100\n",
        "    n= 0\n",
        "    buy_price = 0\n",
        "    budget+=present_state*n\n",
        "  else :                                   #hold\n",
        "    PnL = 0\n",
        "  if budget < min_budget :\n",
        "    PnL = (min_budget - budget)*penalty_factor\n",
        "  return PnL ,buy_price , n , budget\n",
        "\n",
        "#Some parameters required set randomly as of now\n",
        "alpha = 0.01   #learning rate\n",
        "gamma = 0.999   #discount\n",
        "epsilon = 0.4   #for explore-exploit trade-off\n",
        "n_iterations = 1000 #number of iterations\n",
        "\n",
        "\n",
        "#Now we are using Q_learning algorith which uses Q-table to predict stock price\n",
        "#Creating the Q-Table and intialising it to 0\n",
        "n_actions = 3      #buy,sell or hold\n",
        "n_states = len(data)\n",
        "q_table = np.random.rand(n_states, n_actions) * 2 - 1\n",
        "\n",
        "#letsdefine somethings before iterating\n",
        "#These n states\n",
        "state_list = []\n",
        "buy_price = 0\n",
        "i=n_states-1\n",
        "t=0\n",
        "while i>0:\n",
        "  temp = State()\n",
        "  temp.val = data[i]\n",
        "  temp.next_val = data[i-1]\n",
        "  temp.q_index = t\n",
        "  state_list.append(temp)\n",
        "  i-=1\n",
        "  t+=1\n",
        "temp.val = data[0]\n",
        "temp.q_index = n_states-1\n",
        "state_list.append(temp)   #list of all n states\n",
        "\n",
        "i=0\n",
        "while i< n_iterations:\n",
        "  epsilon-=0.0004\n",
        "  buy_price = 0\n",
        "  n_stocks =0\n",
        "  initial_amount = 5000\n",
        "  budget = 5000\n",
        "  j=0\n",
        "  while j< n_states-1 :\n",
        "     state = state_list[j]\n",
        "     if np.random.uniform() < epsilon :\n",
        "      action =  take_random_action (n_stocks, budget)  # Explore (random action)\n",
        "     else:\n",
        "      action = np.argmax(q_table[state.q_index, :])  # Exploit (best action)\n",
        "      if n_stocks == 0 :\n",
        "        check = max(q_table[state.q_index, 0],q_table[state.q_index, 1])\n",
        "      if check == q_table[state.q_index, 0] and budget>state.val :\n",
        "        action=0\n",
        "      else :\n",
        "        action = 1\n",
        "     reward , buy_price , n_stocks , budget = get_reward(state.val,state.next_val,action,buy_price,n_stocks , budget)\n",
        "     q_table[j ,int(action)] =  (1-alpha)*q_table[j, int(action)] + \\\n",
        "                            alpha * (reward + gamma * np.max(q_table[j+1, :]))\n",
        "     j+=1\n",
        "  i+=1\n",
        "print(q_table)\n",
        "print(state.val*n_stocks + budget)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dNLUUmHvLRPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77dd1ec-a262-43ea-dd4f-2db28ac88548"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.31423875e-01  6.62965541e-01  6.13861244e-01]\n",
            " [-8.61338365e-01  6.95252837e-01 -2.02952283e-01]\n",
            " [-6.38525128e-02  7.29960037e-01  2.63612389e-01]\n",
            " ...\n",
            " [-5.75165879e-01 -8.44037567e+02 -1.14066459e-01]\n",
            " [ 4.03787350e-01 -8.44441850e+02  7.05790800e-01]\n",
            " [-5.30371630e-01  2.35476501e-01  3.01057195e-01]]\n",
            "12002.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "returns = ((state.val*n_stocks + budget-initial_amount)/initial_amount)*100\n",
        "returns"
      ],
      "metadata": {
        "id": "9MynYtIbJhaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Now lets make a model without budget constraint**(In progress)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "BTHmojGE2oZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we define state of the stocks for now i have simply chosen state to include stock price\n",
        "#will update it later to consider other things too\n",
        "\n",
        "class State :\n",
        "  def __init__(self):\n",
        "    self.prev_val = None\n",
        "    self.next_val = None\n",
        "    self.val = None\n",
        "    self.avg= None\n",
        "    self.volume = None\n",
        "    self.q_index = None\n",
        "\n",
        "\n",
        "#This is a function which randomizes the action function\n",
        "def take_random_action (n) :\n",
        "  if n==0 :\n",
        "    return np.random.randint(0,2)\n",
        "  action = np.random.randint(0,3)\n",
        "  return action\n",
        "\n",
        "\n",
        "#here we define the reward function for now we are choosing the reward function to be simply PnL\n",
        "#Can be modified later\n",
        "def get_reward(present_state,Post_state,action,buy_price,n, budget) :\n",
        "  if action==0 :                              #  buy\n",
        "    PnL = (Post_state-present_state)*(n-1)\n",
        "    buy_price+=present_state\n",
        "    PnL = (PnL/buy_price)*100\n",
        "    n+=1\n",
        "    budget-=present_state\n",
        "  elif action ==2 and n !=0 :                             #sell\n",
        "    PnL = (n*present_state - buy_price)\n",
        "    PnL = (PnL/buy_price) * 100\n",
        "    n= 0\n",
        "    buy_price = 0\n",
        "    budget+=present_state*n\n",
        "  else :                                   #hold\n",
        "    PnL = 0\n",
        "  return PnL ,buy_price , n , budget\n",
        "\n",
        "#Some parameters required set randomly as of now\n",
        "alpha = 0.05   #learning rate\n",
        "gamma = 0.8   #discount\n",
        "epsilon = 0.08    #for explore-exploit trade-off\n",
        "n_iterations = 2000  #number of iterations\n",
        "\n",
        "\n",
        "#Now we are using Q_learning algorith which uses Q-table to predict stock price\n",
        "#Creating the Q-Table and intialising it to 0\n",
        "n_actions = 3      #buy,sell or hold\n",
        "n_states = len(data)\n",
        "q_table = np.zeros((n_states, n_actions))\n",
        "\n",
        "#letsdefine somethings before iterating\n",
        "#These n states\n",
        "state_list = []\n",
        "buy_price = 0\n",
        "n_stocks =0\n",
        "budget = 0\n",
        "i=n_states-1\n",
        "t=0\n",
        "while i>0:\n",
        "  temp = State()\n",
        "  temp.val = data[i]\n",
        "  temp.next_val = data[i-1]\n",
        "  temp.q_index = t\n",
        "  state_list.append(temp)\n",
        "  i-=1\n",
        "  t+=1\n",
        "temp.val = data[0]\n",
        "temp.q_index = 2354\n",
        "state_list.append(temp)   #list of all n states\n",
        "\n",
        "i=0\n",
        "while i< n_iterations:\n",
        "  j=0\n",
        "  while j< n_states-1 :\n",
        "     state = state_list[j]\n",
        "     if np.random.uniform() < epsilon :\n",
        "      action =  take_random_action (n_stocks)  # Explore (random action)\n",
        "     else:\n",
        "      action = np.argmax(q_table[state.q_index, :])  # Exploit (best action)\n",
        "     reward , buy_price , n_stocks , budget = get_reward(state.val,state.next_val,action,buy_price,n_stocks , budget)\n",
        "     q_table[j ,action] = (1 - alpha) * q_table[j, action] + \\\n",
        "                            alpha * (reward + gamma * np.max(q_table[j+1, :]))\n",
        "     j+=1\n",
        "  i+=1\n",
        "print(action)\n",
        "print(q_table)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eCda8BoZNQfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#Here we define state of the stocks for now i have simply chosen state to include stock price\n",
        "#will update it later to consider other things too\n",
        "\n",
        "class State :\n",
        "  def __init__(self):\n",
        "    self.prev_val = None\n",
        "    self.next_val = None\n",
        "    self.val = None\n",
        "    self.avg= None\n",
        "    self.volume = None\n",
        "    self.q_index = None\n",
        "\n",
        "\n",
        "#This is a function which randomizes the action function\n",
        "def take_random_action (n) :\n",
        "  if n==0 :\n",
        "      return 0\n",
        "  action = np.random.randint(1,3)\n",
        "  return action\n",
        "\n",
        "\n",
        "#here we define the reward function for now we are choosing the reward function to be simply PnL\n",
        "#Can be modified later\n",
        "def get_reward(present_state,Post_state,action,buy_price,n) :\n",
        "  if action==0 :                              #  buy\n",
        "    PnL = (Post_state-present_state)*n\n",
        "    buy_price=present_state\n",
        "    n+=1\n",
        "  elif action ==2 :                             #sell\n",
        "    PnL = (present_state - buy_price)\n",
        "    n= 0\n",
        "    buy_price = 0\n",
        "  else :                                   #hold\n",
        "    PnL = 0\n",
        "  return PnL ,buy_price , n\n",
        "\n",
        "#Some parameters required set randomly as of now\n",
        "alpha = 0.1   #learning rate\n",
        "gamma = 0.9   #discount\n",
        "epsilon = 0.9    #for explore-exploit trade-off\n",
        "n_iterations = 500   #number of iterations\n",
        "\n",
        "\n",
        "#Now we are using Q_learning algorith which uses Q-table to predict stock price\n",
        "#Creating the Q-Table and intialising it to 0\n",
        "n_actions = 3      #buy,sell or hold\n",
        "n_states = len(data)\n",
        "q_table = np.zeros((n_states, n_actions))\n",
        "\n",
        "#letsdefine somethings before iterating\n",
        "#These n states\n",
        "state_list = []\n",
        "buy_price = data[0]\n",
        "n_stocks =1\n",
        "i=0\n",
        "while i< n_states-1:\n",
        "  temp = State()\n",
        "  temp.val = data[i]\n",
        "  temp.next_val = data[i+1]\n",
        "  temp.q_index = i\n",
        "  state_list.append(temp)\n",
        "  i+=1\n",
        "temp.val = data[n_states-1]\n",
        "temp.q_index = n_states-1\n",
        "state_list.append(temp)   #list of all n states\n",
        "\n",
        "i=0\n",
        "while i< n_iterations:\n",
        "  j=0\n",
        "  while j< n_states-2 :\n",
        "     state = state_list[j]\n",
        "     if np.random.uniform() < epsilon :\n",
        "      action =  take_random_action (n_stocks)  # Explore (random action)\n",
        "     else:\n",
        "      action = np.argmax(q_table[state.q_index, :])  # Exploit (best action)\n",
        "      if n_stocks ==1 :\n",
        "        action = np.random.randint(1,3)\n",
        "     reward , buy_price , n_stocks = get_reward(state.val,state.next_val,action,buy_price,n_stocks)\n",
        "     q_table[int(state.q_index) ,action] = (1 - alpha) * q_table[int(state.q_index), action] + \\\n",
        "                            alpha * (reward + gamma * np.max(q_table[int(state.q_index +1), :]))\n",
        "     j+=1\n",
        "  i+=1\n",
        "print(q_table)\n"
      ],
      "metadata": {
        "id": "3X71gjNcJ7YM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}